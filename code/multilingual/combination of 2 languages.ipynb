{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gMmwjFPMoQLP"
      },
      "outputs": [],
      "source": [
        "#multilingual 2 languages test all languages\n",
        "from itertools import combinations\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, get_linear_schedule_with_warmup\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Load and clean dataset functions\n",
        "def load_data(filepath):\n",
        "    if filepath.endswith('.csv'):\n",
        "        return pd.read_csv(filepath)\n",
        "    elif filepath.endswith('.xlsx'):\n",
        "        return pd.read_excel(filepath)\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported file format: {filepath}\")\n",
        "\n",
        "def clean_dataset(df):\n",
        "    if 'title' not in df.columns or 'label' not in df.columns:\n",
        "        raise ValueError(\"The dataframe must have 'title' and 'label' columns.\")\n",
        "\n",
        "    df = df.dropna(subset=['title', 'label'])  # Ensure no NaNs in title or label\n",
        "    df = df[df['title'].apply(lambda x: isinstance(x, str) and len(x.strip()) > 0)]  # Ensure non-empty strings\n",
        "    df = df[df['label'].apply(lambda x: isinstance(x, (int, np.integer)) or str(x).isdigit())]  # Ensure valid labels\n",
        "\n",
        "    df['title'] = df['title'].astype(str)\n",
        "    df['label'] = df['label'].astype(int)\n",
        "    return df\n",
        "\n",
        "# Dataset wrapper to handle input data\n",
        "class DatasetWrapper(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "def create_data_loader(texts, labels, tokenizer, max_len, batch_size):\n",
        "    print(f\"Texts to tokenize: {texts[:5]}\")  # Print the first 5 texts for debugging\n",
        "    print(f\"Labels: {labels[:5]}\")            # Print the corresponding labels\n",
        "\n",
        "    # Filter out any potential empty strings in the texts\n",
        "    valid_data = [(text, label) for text, label in zip(texts, labels) if text.strip()]\n",
        "\n",
        "    # Separate valid texts and labels\n",
        "    valid_texts, valid_labels = zip(*valid_data) if valid_data else ([], [])\n",
        "\n",
        "    if len(valid_texts) == 0:\n",
        "        raise ValueError(\"No valid texts found after filtering.\")\n",
        "\n",
        "    encoding = tokenizer(\n",
        "        valid_texts,\n",
        "        truncation=True,\n",
        "        padding=True,\n",
        "        max_length=max_len,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "\n",
        "    dataset = DatasetWrapper(encoding, valid_labels)\n",
        "    return DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Training and evaluation functions\n",
        "def train_epoch(model, data_loader, loss_fn, optimizer, device, scheduler, dataset_len):\n",
        "    model.train()\n",
        "    losses = []\n",
        "    correct_predictions = 0\n",
        "\n",
        "    for data in data_loader:\n",
        "        input_ids = data['input_ids'].to(device)\n",
        "        attention_mask = data['attention_mask'].to(device)\n",
        "        labels = data['labels'].to(device)\n",
        "\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        _, preds = torch.max(outputs.logits, dim=1)\n",
        "        correct_predictions += torch.sum(preds == labels)\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "    return correct_predictions.double() / dataset_len, np.mean(losses)\n",
        "\n",
        "def eval_model(model, data_loader, loss_fn, device, dataset_len):\n",
        "    model.eval()\n",
        "    losses = []\n",
        "    correct_predictions = 0\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in data_loader:\n",
        "            input_ids = data['input_ids'].to(device)\n",
        "            attention_mask = data['attention_mask'].to(device)\n",
        "            labels = data['labels'].to(device)\n",
        "\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            _, preds = torch.max(outputs.logits, dim=1)\n",
        "            correct_predictions += torch.sum(preds == labels)\n",
        "            losses.append(loss.item())\n",
        "\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "\n",
        "    return correct_predictions.double() / dataset_len, np.mean(losses), all_labels, all_preds\n",
        "\n",
        "# Main function\n",
        "def main():\n",
        "    RANDOM_SEED = 42\n",
        "    MAX_LEN = 128\n",
        "    BATCH_SIZE = 16\n",
        "    EPOCHS = 3\n",
        "    TEST_SPLIT = 0.2\n",
        "    PATIENCE = 3  # Early stopping patience\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f'Using device: {device}')\n",
        "\n",
        "    languages = ['hebrew', 'arabic', 'bangla', 'chinese', 'english', 'german', 'indonesian', 'romanian', 'turkish']\n",
        "    file_paths = {\n",
        "        'hebrew': '/hebrew.xlsx',\n",
        "        'arabic': '/arabic.xlsx',\n",
        "        'bangla': '/bangla.csv',\n",
        "        'chinese': '/chinese.csv',\n",
        "        'english': '/english.csv',\n",
        "        'german': '/german.csv',\n",
        "        'indonesian': '/indonesian.csv',\n",
        "        'romanian': '/romanianL.xlsx',\n",
        "        'turkish': '/turkish.csv'\n",
        "    }\n",
        "\n",
        "    results = []\n",
        "    tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
        "\n",
        "    # Iterate over combinations of 2 languages\n",
        "    for lang_comb in combinations(languages, 2):\n",
        "        print(f\"Processing combination: {lang_comb}\")\n",
        "\n",
        "        # Load and clean datasets for the two languages\n",
        "        df_lang1 = load_data(file_paths[lang_comb[0]])\n",
        "        df_lang1 = clean_dataset(df_lang1)\n",
        "\n",
        "        df_lang2 = load_data(file_paths[lang_comb[1]])\n",
        "        df_lang2 = clean_dataset(df_lang2)\n",
        "\n",
        "        # Split each dataset into 80% train and 20% test\n",
        "        train_size_lang1 = int(len(df_lang1) * (1 - TEST_SPLIT))\n",
        "        train_size_lang2 = int(len(df_lang2) * (1 - TEST_SPLIT))\n",
        "\n",
        "        df_train_lang1_indices, df_test_lang1_indices = random_split(df_lang1, [train_size_lang1, len(df_lang1) - train_size_lang1])\n",
        "        df_train_lang2_indices, df_test_lang2_indices = random_split(df_lang2, [train_size_lang2, len(df_lang2) - train_size_lang2])\n",
        "\n",
        "        # Convert Subset objects back into Pandas DataFrames\n",
        "        df_train_lang1 = df_lang1.iloc[df_train_lang1_indices.indices]\n",
        "        df_test_lang1 = df_lang1.iloc[df_test_lang1_indices.indices]\n",
        "\n",
        "        df_train_lang2 = df_lang2.iloc[df_train_lang2_indices.indices]\n",
        "        df_test_lang2 = df_lang2.iloc[df_test_lang2_indices.indices]\n",
        "\n",
        "        # Combine train datasets of the two languages\n",
        "        df_train_combined = pd.concat([df_train_lang1, df_train_lang2], ignore_index=True)\n",
        "\n",
        "        # Create DataLoaders\n",
        "        train_data_loader = create_data_loader(\n",
        "            df_train_combined['title'].tolist(),\n",
        "            df_train_combined['label'].tolist(),\n",
        "            tokenizer,\n",
        "            MAX_LEN,\n",
        "            BATCH_SIZE\n",
        "        )\n",
        "        test_data_loader_lang1 = create_data_loader(\n",
        "            df_test_lang1['title'].tolist(),\n",
        "            df_test_lang1['label'].tolist(),\n",
        "            tokenizer,\n",
        "            MAX_LEN,\n",
        "            BATCH_SIZE\n",
        "        )\n",
        "        test_data_loader_lang2 = create_data_loader(\n",
        "            df_test_lang2['title'].tolist(),\n",
        "            df_test_lang2['label'].tolist(),\n",
        "            tokenizer,\n",
        "            MAX_LEN,\n",
        "            BATCH_SIZE\n",
        "        )\n",
        "\n",
        "        # Initialize model\n",
        "        model = BertForSequenceClassification.from_pretrained('bert-base-multilingual-cased', num_labels=2)\n",
        "        model = model.to(device)\n",
        "\n",
        "        optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
        "        total_steps = len(train_data_loader) * EPOCHS\n",
        "        scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
        "        loss_fn = torch.nn.CrossEntropyLoss().to(device)\n",
        "\n",
        "        best_loss = float('inf')\n",
        "        patience_counter = 0\n",
        "\n",
        "        # Training loop\n",
        "        for epoch in range(EPOCHS):\n",
        "            print(f'Starting epoch {epoch + 1}/{EPOCHS}')\n",
        "            train_acc, train_loss = train_epoch(\n",
        "                model,\n",
        "                train_data_loader,\n",
        "                loss_fn,\n",
        "                optimizer,\n",
        "                device,\n",
        "                scheduler,\n",
        "                len(df_train_combined)\n",
        "            )\n",
        "            print(f'Train loss {train_loss}, accuracy {train_acc}')\n",
        "\n",
        "        # Evaluate on the two test sets separately\n",
        "        print(f'Evaluating on {lang_comb[0]} test set...')\n",
        "        test_acc_lang1, test_loss_lang1, labels_lang1, preds_lang1 = eval_model(\n",
        "            model,\n",
        "            test_data_loader_lang1,\n",
        "            loss_fn,\n",
        "            device,\n",
        "            len(df_test_lang1)\n",
        "        )\n",
        "        precision_lang1 = precision_score(labels_lang1, preds_lang1, average='weighted')\n",
        "        recall_lang1 = recall_score(labels_lang1, preds_lang1, average='weighted')\n",
        "        f1_lang1 = f1_score(labels_lang1, preds_lang1, average='weighted')\n",
        "\n",
        "        print(f'Evaluating on {lang_comb[1]} test set...')\n",
        "        test_acc_lang2, test_loss_lang2, labels_lang2, preds_lang2 = eval_model(\n",
        "            model,\n",
        "            test_data_loader_lang2,\n",
        "            loss_fn,\n",
        "            device,\n",
        "            len(df_test_lang2)\n",
        "        )\n",
        "        precision_lang2 = precision_score(labels_lang2, preds_lang2, average='weighted')\n",
        "        recall_lang2 = recall_score(labels_lang2, preds_lang2, average='weighted')\n",
        "        f1_lang2 = f1_score(labels_lang2, preds_lang2, average='weighted')\n",
        "\n",
        "        # Save results for the current combination\n",
        "        results.append({\n",
        "            'languages': lang_comb,\n",
        "            'test_results_lang1': {\n",
        "                'accuracy': test_acc_lang1.item(),\n",
        "                'precision': precision_lang1,\n",
        "                'recall': recall_lang1,\n",
        "                'f1': f1_lang1\n",
        "            },\n",
        "            'test_results_lang2': {\n",
        "                'accuracy': test_acc_lang2.item(),\n",
        "                'precision': precision_lang2,\n",
        "                'recall': recall_lang2,\n",
        "                'f1': f1_lang2\n",
        "            }\n",
        "        })\n",
        "\n",
        "    print(f\"Final results: {results}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ]
}